Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
12000,1.4189383,21.78409090909091,-0.15498056,1.1752851378781715,1.1752851378781715,1.0
24000,1.4095556,23.466395112016293,-0.054644834,1.343902391873724,1.343902391873724,1.0
36000,1.3963348,27.56904761904762,0.115183964,1.7646777316892346,1.7646777316892346,1.0
48000,1.3811985,36.05263157894737,0.28060347,2.5984568069746463,2.5984568069746463,1.0
60000,1.3599001,56.893719806763286,0.5919593,4.648077392807374,4.648077392807374,1.0
72000,1.3429188,101.35833333333333,0.8658756,8.890001246333123,8.890001246333123,1.0
84000,1.3305674,199.33898305084745,1.281184,18.536669498682024,18.536669498682024,1.0
96000,1.3199613,371.25,1.6894412,36.89063074439764,36.89063074439764,1.0
108000,1.3114688,780.625,2.2490091,73.01251108944416,73.01251108944416,1.0
120000,1.3027897,848.6428571428571,2.834269,84.65001283373151,84.65001283373151,1.0
132000,1.2954093,878.6428571428571,3.344528,87.72858483450753,87.72858483450753,1.0
144000,1.2866303,906.6153846153846,3.7946858,90.50770715566782,90.50770715566782,1.0
156000,1.2742234,985.0,4.2024903,98.50834846496582,98.50834846496582,1.0
168000,1.268467,999.0,4.582401,100.00001525878906,100.00001525878906,1.0
180000,1.2638103,997.4166666666666,5.0186954,99.75001525878906,99.75001525878906,1.0
192000,1.2645004,952.9230769230769,5.42584,95.30770697960487,95.30770697960487,1.0
204000,1.263501,999.0,5.727344,100.00001525878906,100.00001525878906,1.0
216000,1.2621334,983.0833333333334,6.0645375,98.31668217976888,98.31668217976888,1.0
